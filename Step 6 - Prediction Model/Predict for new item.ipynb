{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random as rd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import klepto\n",
    "import shelve\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "from scipy.sparse import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shelve\n",
    "import pickle\n",
    "with shelve.open(\"./1m/1 - ss/P_test.pkl\", protocol=pickle.HIGHEST_PROTOCOL) as d:\n",
    "    P_test_tree1 = d['content']\n",
    "with shelve.open(\"./1m/1 - ss/rated_matrix.pkl\", protocol=pickle.HIGHEST_PROTOCOL) as d:\n",
    "    rated_matrix_tree1 = d['content']\n",
    "P_test_tree1 = P_test_tree1.tocsc().toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "import pickle\n",
    "with shelve.open(\"./1m/2 - ss/P_test.pkl\", protocol=pickle.HIGHEST_PROTOCOL) as d:\n",
    "    P_test_tree2 = d['content']\n",
    "with shelve.open(\"./1m/2 - ss/rated_matrix.pkl\", protocol=pickle.HIGHEST_PROTOCOL) as d:\n",
    "    rated_matrix_tree2 = d['content']\n",
    "P_test_tree2 = P_test_tree2.tocsc().toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shelve\n",
    "import pickle\n",
    "with shelve.open(\"./1m/3 - ss/P_test.pkl\", protocol=pickle.HIGHEST_PROTOCOL) as d:\n",
    "    P_test_tree3 = d['content']\n",
    "with shelve.open(\"./1m/3 - ss/rated_matrix.pkl\", protocol=pickle.HIGHEST_PROTOCOL) as d:\n",
    "    rated_matrix_tree3 = d['content']\n",
    "P_test_tree3 = P_test_tree3.tocsc().toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_model = {1: {'P_test': P_test_tree1, 'rated_matrix': rated_matrix_tree1},\n",
    "                    2: {'P_test': P_test_tree2, 'rated_matrix': rated_matrix_tree2},\n",
    "                    3: {'P_test': P_test_tree3, 'rated_matrix': rated_matrix_tree3}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Test item info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = '1m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=h5py.File(dataset + '/test_list.mat')  \n",
    "test_list = feature['test_list'][:]\n",
    "test_list = list(map(int, test_list.T[0]))\n",
    "test_list = [i-1 for i in test_list] \n",
    "feature=h5py.File(dataset + '/train_list.mat')\n",
    "train_list = feature['train_list'][:]\n",
    "train_list = list(map(int, train_list.T[0]))\n",
    "train_list = [i-1 for i in train_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file load DONE\n"
     ]
    }
   ],
   "source": [
    "rating_matrix = load_npz('sparse_matrix_ml-' + dataset + '_selected.npz').tocsc()\n",
    "rating_matrix_train = rating_matrix[:, train_list]\n",
    "rating_matrix_test  = rating_matrix[:, test_list]\n",
    "print(\"file load DONE\")\n",
    "rating_matrix_test = rating_matrix_test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Three Tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1 = []\n",
    "lst2 = []\n",
    "lst3 = []\n",
    "for itemid in range(rating_matrix_test.shape[1]):\n",
    "    model_ind = rd.randint(1, 3)\n",
    "    if model_ind == 1:\n",
    "        lst1.append(itemid)\n",
    "    elif model_ind == 2:\n",
    "        lst2.append(itemid)\n",
    "    elif model_ind == 3:\n",
    "        lst3.append(itemid)\n",
    "\n",
    "P_test1 = prediction_model[1]['P_test'][:, lst1]\n",
    "P_test2 = prediction_model[2]['P_test'][:, lst2]\n",
    "P_test3 = prediction_model[3]['P_test'][:, lst3]\n",
    "rated_user1 = prediction_model[1]['rated_matrix'][:, lst1]\n",
    "rated_user2 = prediction_model[2]['rated_matrix'][:, lst2]\n",
    "rated_user3 = prediction_model[3]['rated_matrix'][:, lst3]\n",
    "rating_matrix_test_unqueried1 = rating_matrix_test[:, lst1] * rated_user1\n",
    "rating_matrix_test_unqueried2 = rating_matrix_test[:, lst2] * rated_user2\n",
    "rating_matrix_test_unqueried3 = rating_matrix_test[:, lst3] * rated_user3\n",
    "\n",
    "dif1 = P_test1*(rating_matrix_test_unqueried1!=0) - rating_matrix_test_unqueried1\n",
    "dif2 = P_test2*(rating_matrix_test_unqueried2!=0) - rating_matrix_test_unqueried2\n",
    "dif3 = P_test3*(rating_matrix_test_unqueried3!=0) - rating_matrix_test_unqueried3\n",
    "RMSE1 = (dif1**2).sum()\n",
    "RMSE2 = (dif2**2).sum()\n",
    "RMSE3 = (dif3**2).sum()\n",
    "RMSE_denominator1 = (rating_matrix_test_unqueried1!=0).sum()\n",
    "RMSE_denominator2 = (rating_matrix_test_unqueried2!=0).sum()\n",
    "RMSE_denominator3 = (rating_matrix_test_unqueried3!=0).sum() \n",
    "nominator1 = np.multiply(P_test1>3, rating_matrix_test_unqueried1>3).sum()\n",
    "denominator1 = (rating_matrix_test_unqueried1>3).sum()\n",
    "nominator2 = np.multiply(P_test2>3, rating_matrix_test_unqueried2>3).sum()\n",
    "denominator2 = (rating_matrix_test_unqueried2>3).sum()\n",
    "nominator3 = np.multiply(P_test3>3, rating_matrix_test_unqueried3>3).sum()\n",
    "denominator3 = (rating_matrix_test_unqueried3>3).sum()\n",
    "\n",
    "RMSE = ( (RMSE1 + RMSE2 + RMSE3) / (RMSE_denominator1 + RMSE_denominator2 + RMSE_denominator3) )**0.5\n",
    "Precision = (nominator1 + nominator2 + nominator3) / (denominator1 + denominator2 + denominator3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92295567526371403"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92662377613108093"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Three Tree models (delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n"
     ]
    }
   ],
   "source": [
    "RMSE = 0\n",
    "nominator = 0\n",
    "denominator = 0\n",
    "size = prediction_model[model_ind]['rated_matrix'].shape[0]\n",
    "for itemid in range(rating_matrix_test.shape[1]):\n",
    "    if itemid % 100 == 0:\n",
    "        print(itemid)\n",
    "    model_ind = rd.randint(1, 3)\n",
    "    P_test = prediction_model[model_ind]['P_test'][:, itemid]\n",
    "    rated_user = prediction_model[model_ind]['rated_matrix'][:, itemid].reshape(size, 1)\n",
    "    rating_matrix_test_unqueried = rating_matrix_test[:, itemid] * rated_user\n",
    "    dif = P_test*(rating_matrix_test_unqueried!=0) - rating_matrix_test_unqueried\n",
    "    RMSE += ( (dif**2).sum() / (rating_matrix_test_unqueried!=0).sum() )**0.5\n",
    "    nominator += np.multiply(P_test>3, rating_matrix_test_unqueried>3).sum()\n",
    "    denominator += (rating_matrix_test_unqueried>3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Precision = nominator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92584767185488959"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
